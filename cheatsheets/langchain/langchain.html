<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <title>LangChainå¼€å‘å‘½ä»¤é€ŸæŸ¥è¡¨</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="../../assets/variables.css">
  <link rel="stylesheet" href="../../assets/global.css">
  <link rel="stylesheet" href="../../assets/cheatsheet.css">
  <link rel="icon" type="image/png" href="../../assets/brand/cheatsheet.png" />
  <link rel="apple-touch-icon" href="../../assets/brand/cheatsheet.png" />

  <!-- Prism.js è¯­æ³•é«˜äº® -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
  <style>
    :root {
      --colWidth: 340px;
      --gap: 16px;
    }
    .panel label {
      color: var(--panel-accent);
    }
    .panel .title {
      color: var(--panel-accent);
    }
  </style>
</head>
<body>
  <div class="container">
    <div class="panel">
      <span class="title">ğŸ¦œğŸ”— LangChainå¼€å‘é€ŸæŸ¥è¡¨</span>
      <label for="columnWidth">ğŸ”§ è°ƒæ•´æ¯åˆ—å®½åº¦ï¼š</label>
      <input id="columnWidth" class="slider-bar" type="range" min="300" max="660" value="340">
      <span id="widthVal" class="slider-val">340px</span>
    </div>
    <div class="cheat-columns" id="columns">
      <div class="card">
        <h2>ğŸ“¦ å®‰è£…ä¸é…ç½® <a href="https://python.langchain.com/docs/introduction/" title="å®˜æ–¹å®‰è£…æŒ‡å—" target="_blank" style="color:#93cdfc;">>></a></h2>
        <ul>
          <li><code>pip install --pre -U langchain</code> | å®‰è£…æœ€æ–°é¢„è§ˆç‰ˆ</li>
          <li><code>uv add langchain</code> | ä½¿ç”¨uvå®‰è£…ï¼ˆæ¨èï¼‰</li>
          <li><code>pip install langchain-core</code> | å®‰è£…æ ¸å¿ƒåº“</li>
          <li><code>pip install langchain-community</code> | ç¤¾åŒºé›†æˆåŒ…</li>
        </ul>
        <h3>æ¨¡å—åŒ–å®‰è£…</h3>
        <pre><code class="language-bash"># OpenAIé›†æˆ
pip install langchain-openai

# Anthropicé›†æˆ
pip install langchain-anthropic

# Googleé›†æˆ
pip install langchain-google-vertexai

# å‘é‡å­˜å‚¨
pip install chromadb faiss-cpu
pip install langchain-qdrant
pip install langchain-milvus

# å¦‚æœéœ€è¦æ—§ç‰ˆåŠŸèƒ½
pip install langchain-classic</code></pre>
        <div class="desc">LangChain v1.0 é‡‡ç”¨æ¨¡å—åŒ–å®‰è£…ï¼ŒæŒ‰éœ€é›†æˆç‰¹å®šç»„ä»¶</div>
      </div>

      <div class="card">
        <h2>ğŸ¤– ç»Ÿä¸€æ¨¡å‹åˆå§‹åŒ– <a href="https://python.langchain.com/docs/integrations/llms/" title="æ¨¡å‹é›†æˆæ–‡æ¡£" target="_blank" style="color:#93cdfc;">>></a></h2>
        <ul>
          <li><code>init_chat_model()</code> | ç»Ÿä¸€LLMåˆå§‹åŒ–</li>
          <li><code>init_embeddings()</code> | ç»Ÿä¸€åµŒå…¥åˆå§‹åŒ–</li>
          <li><code>æä¾›å•†æ ‡è¯†ç¬¦</code> | è‡ªåŠ¨é€‰æ‹©åˆé€‚æä¾›å•†</li>
          <li><code>é…ç½®å‚æ•°</code> | æ”¯æŒæ‰€æœ‰LLMå‚æ•°</li>
        </ul>
        <h3>æ¨¡å‹åˆå§‹åŒ–ç¤ºä¾‹</h3>
        <pre><code class="language-python">from langchain.chat_models import init_chat_model
from langchain.embeddings import init_embeddings

# ç»Ÿä¸€åˆå§‹åŒ–æ–¹å¼
llm = init_chat_model("openai:gpt-4o-mini")
embeddings = init_embeddings("openai:text-embedding-3-large")

# æ”¯æŒå¤šç§æä¾›å•†
llm = init_chat_model("anthropic:claude-sonnet-4-20250514")
llm = init_chat_model("google:gemini-pro")
llm = init_chat_model("cohere:command-r-plus")

# é…ç½®å‚æ•°
llm = init_chat_model(
    "openai:gpt-4o",
    temperature=0.7,
    max_tokens=1000,
    streaming=True,
    timeout=30
)</code></pre>
        <div class="desc">æ–°APIæä¾›ç»Ÿä¸€çš„åˆå§‹åŒ–æ¥å£ï¼Œç®€åŒ–æ¨¡å‹åˆ‡æ¢</div>
      </div>

      <div class="card">
        <h2>ğŸ“ é«˜çº§Promptæ¨¡æ¿ <a href="https://python.langchain.com/docs/concepts/prompt_templates/" title="Promptæ¨¡æ¿æ–‡æ¡£" target="_blank" style="color:#93cdfc;">>></a></h2>
        <ul>
          <li><code>ChatPromptTemplate</code> | èŠå¤©æ¶ˆæ¯æ¨¡æ¿</li>
          <li><code>FewShotPromptTemplate</code> | å°‘æ ·æœ¬å­¦ä¹ æ¨¡æ¿</li>
          <li><code>PipelinePromptTemplate</code> | å¤šçº§ç®¡é“æ¨¡æ¿</li>
          <li><code>ç¤ºä¾‹é©±åŠ¨</code> | æ”¯æŒç¤ºä¾‹å’Œæ ¼å¼åŒ–</li>
        </ul>
        <h3>é«˜çº§æ¨¡æ¿ç¤ºä¾‹</h3>
        <pre><code class="language-python">from langchain_core.prompts import (
    ChatPromptTemplate,
    FewShotPromptTemplate,
    PipelinePromptTemplate
)

# èŠå¤©æ¨¡æ¿
chat_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ©æ‰‹"),
    ("user", "{input}"),
    ("assistant", "{response}"),
    ("user", "{followup}")
])

# å°‘æ ·æœ¬æ¨¡æ¿
examples = [
    {"input": "2+2", "output": "4"},
    {"input": "3*5", "output": "15"}
]

few_shot = FewShotPromptTemplate(
    examples=examples,
    example_prompt=PromptTemplate.from_template(
        "è¾“å…¥: {input}\nè¾“å‡º: {output}"
    ),
    prefix="è§£å†³ä»¥ä¸‹æ•°å­¦é—®é¢˜ï¼š",
    suffix="\nè¾“å…¥: {question}\nè¾“å‡ºï¼š",
    input_variables=["question"]
)

# ç®¡é“æ¨¡æ¿
final_prompt = PipelinePromptTemplate(
    final_prompt=PromptTemplate.from_template(
        "{background}\n\n{task}\n\nä¸Šä¸‹æ–‡ï¼š{context}\n\n{question}"
    ),
    pipeline_prompts=[
        ("background", PromptTemplate.from_template("èƒŒæ™¯ï¼š{bg}")),
        ("task", PromptTemplate.from_template("ä»»åŠ¡ï¼š{task}")),
        ("context", PromptTemplate.from_template("ä¸Šä¸‹æ–‡ï¼š{context}"))
    ]
)</code></pre>
        <div class="desc">é«˜çº§æ¨¡æ¿æ”¯æŒå¤æ‚æç¤ºå·¥ç¨‹å’Œç¤ºä¾‹é©±åŠ¨</div>
      </div>

      <div class="card">
        <h2>ğŸ”— LCEL v1.0é“¾å¼è°ƒç”¨ <a href="https://python.langchain.com/docs/concepts/lcel/" title="LCELæ–‡æ¡£" target="_blank" style="color:#93cdfc;">>></a></h2>
        <ul>
          <li><code>ç®¡é“æ“ä½œç¬¦ |</code> | ç»„ä»¶é“¾å¼ç»„åˆ</li>
          <li><code>create_*</code> | ä¸“ç”¨é“¾åˆ›å»ºå‡½æ•°</li>
          <li><code>RunnableParallel</code> | å¹¶è¡Œæ‰§è¡Œç»„ä»¶</li>
          <li><code>ç»“æ„åŒ–è¾“å‡º</code> | ç±»å‹å®‰å…¨çš„ç»“æœè§£æ</li>
        </ul>
        <h3>é«˜çº§é“¾ç»„åˆç¤ºä¾‹</h3>
        <pre><code class="language-python">from langchain_core.chains import (
    create_structured_output_chain,
    create_retrieval_chain,
    create_history_aware_retriever_chain
)
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.runnables import RunnableParallel
from pydantic import BaseModel, Field

# ç»“æ„åŒ–è¾“å‡ºé“¾
class Answer(BaseModel):
    answer: str = Field(description="é—®é¢˜ç­”æ¡ˆ")
    confidence: float = Field(description="ç½®ä¿¡åº¦")

structured_chain = create_structured_output_chain(
    llm=llm,
    prompt=prompt,
    output_schema=Answer
)

# å†å²æ„ŸçŸ¥æ£€ç´¢å™¨
retriever_chain = create_history_aware_retriever_chain(
    llm=llm,
    retriever=vectorstore.as_retriever(),
    rephrase_prompt=ChatPromptTemplate.from_template("""
    åŸºäºèŠå¤©å†å²å’Œæœ€æ–°é—®é¢˜ç”Ÿæˆæ£€ç´¢æŸ¥è¯¢ã€‚
    èŠå¤©å†å²ï¼š{chat_history}
    æœ€æ–°é—®é¢˜ï¼š{input}
    æ£€ç´¢æŸ¥è¯¢ï¼š""")
)

# å¹¶è¡Œæ‰§è¡Œ
parallel_chain = RunnableParallel({
    "analysis": analysis_chain,
    "summary": summary_chain,
    "recommendations": recommendation_chain
})

# å®Œæ•´çš„æ£€ç´¢é“¾
retrieval_chain = create_retrieval_chain(
    llm=llm,
    retriever=vectorstore.as_retriever()
)

result = retrieval_chain.invoke({
    "input": "é—®é¢˜å†…å®¹",
    "chat_history": []
})</code></pre>
        <div class="desc">LCEL v1.0æä¾›æ›´å¼ºçš„ç±»å‹å®‰å…¨å’Œç»„åˆèƒ½åŠ›</div>
      </div>

      <div class="card">
        <h2>ğŸ¯ LangGraphä»£ç†ç³»ç»Ÿ <a href="https://python.langchain.com/docs/concepts/agents/" title="LangGraphæ–‡æ¡£" target="_blank" style="color:#93cdfc;">>></a></h2>
        <ul>
          <li><code>create_react_agent</code> | åˆ›å»ºReactä»£ç†</li>
          <li><code>create_agent()</code> | v1.0æ ‡å‡†ä»£ç†åˆ›å»º</li>
          <li><code>ToolStrategy</code> | ç»“æ„åŒ–è¾“å‡ºç­–ç•¥</li>
          <li><code>é¢„æ„å»ºä»£ç†</code> | å¤šç§ä»£ç†ç±»å‹é€‰æ‹©</li>
        </ul>
        <h3>LangGraphä»£ç†ç¤ºä¾‹</h3>
        <pre><code class="language-python">from langgraph.prebuilt import create_react_agent
from langchain.agents import create_agent
from langchain.agents.structured_output import ToolStrategy

# Reactä»£ç†ï¼ˆæ¨èï¼‰
react_agent = create_react_agent(
    model="claude-sonnet-4-5-20250929",
    tools=tools,
    state_modifier="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ï¼Œèƒ½å¤Ÿä½¿ç”¨å·¥å…·è§£å†³é—®é¢˜ã€‚"
)

# v1.0æ ‡å‡†ä»£ç†
from pydantic import BaseModel, Field

class ContactInfo(BaseModel):
    name: str = Field(description="è”ç³»äººå§“å")
    email: str = Field(description="é‚®ç®±åœ°å€")
    phone: str = Field(description="ç”µè¯å·ç ")

agent = create_agent(
    model="openai:gpt-4o-mini",
    tools=[search_tool, email_tool],
    response_format=ToolStrategy(ContactInfo)
)

result = agent.invoke({
    "messages": [
        {"role": "user", "content": "æå–è”ç³»ä¿¡æ¯ï¼šJohn Doe, john@example.com, (555) 123-4567"}
    ]
})

# ç»“æ„åŒ–ç»“æœ
contact_info = result["structured_response"]
print(f"å§“åï¼š{contact_info.name}")
print(f"é‚®ç®±ï¼š{contact_info.email}")
print(f"ç”µè¯ï¼š{contact_info.phone}")</code></pre>
        <div class="desc">LangGraphæä¾›æ›´å¼ºçš„çŠ¶æ€ç®¡ç†å’Œæ‰§è¡Œæ§åˆ¶</div>
      </div>

      <div class="card">
        <h2>ğŸ› ï¸ é«˜çº§å·¥å…·å®šä¹‰ <a href="https://python.langchain.com/docs/concepts/tools/" title="å·¥å…·æ–‡æ¡£" target="_blank" style="color:#93cdfc;">>></a></h2>
        <ul>
          <li><code>@toolè£…é¥°å™¨</code> | å¿«é€Ÿå·¥å…·å®šä¹‰</li>
          <li><code>ç±»å‹æç¤º</code> | è‡ªåŠ¨å‚æ•°éªŒè¯</li>
          <li><code>å¤æ‚ç±»å‹</code> | æ”¯æŒåµŒå¥—å¯¹è±¡å’Œåˆ—è¡¨</li>
          <li><code>å¼‚æ­¥æ”¯æŒ</code> | åŸç”Ÿå¼‚æ­¥å·¥å…·</li>
        </ul>
        <h3>é«˜çº§å·¥å…·ç¤ºä¾‹</h3>
        <pre><code class="language-python">from langchain.tools import tool
from typing import List, Dict, Optional
import requests
import asyncio

@tool
def search_web(query: str, max_results: int = 5) -> List[Dict]:
    """æœç´¢ç½‘ç»œä¿¡æ¯å¹¶è¿”å›ç»“æœåˆ—è¡¨

    Args:
        query: æœç´¢å…³é”®è¯
        max_results: æœ€å¤§ç»“æœæ•°é‡ï¼ˆé»˜è®¤5ï¼‰
    """
    response = requests.get(f"https://api.search.example.com/search", params={
        "q": query,
        "limit": max_results
    })
    return response.json().get("results", [])

@tool
async def async_database_query(
    sql: str,
    database: str = "primary"
) -> Dict:
    """å¼‚æ­¥æŸ¥è¯¢æ•°æ®åº“

    Args:
        sql: SQLæŸ¥è¯¢è¯­å¥
        database: æ•°æ®åº“åç§°ï¼ˆé»˜è®¤primaryï¼‰
    """
    await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
    return {"status": "success", "data": f"æŸ¥è¯¢ç»“æœï¼š{sql}"}

@tool
def file_operations(
    operation: str,
    path: str,
    content: Optional[str] = None
) -> str:
    """æ–‡ä»¶æ“ä½œå·¥å…·

    Args:
        operation: æ“ä½œç±»å‹ï¼ˆread/write/deleteï¼‰
        path: æ–‡ä»¶è·¯å¾„
        content: å†™å…¥å†…å®¹ï¼ˆä»…å†™æ“ä½œéœ€è¦ï¼‰
    """
    if operation == "read":
        with open(path, 'r', encoding='utf-8') as f:
            return f.read()
    elif operation == "write":
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)
        return f"æˆåŠŸå†™å…¥ï¼š{path}"
    elif operation == "delete":
        import os
        os.remove(path)
        return f"æˆåŠŸåˆ é™¤ï¼š{path}"

tools = [search_web, async_database_query, file_operations]</code></pre>
        <div class="desc">å·¥å…·å®šä¹‰æ”¯æŒå¤æ‚å‚æ•°ã€å¼‚æ­¥æ“ä½œå’Œç±»å‹å®‰å…¨</div>
      </div>

      <div class="card">
        <h2>ğŸ’¾ æ‰©å±•å‘é‡å­˜å‚¨ <a href="https://python.langchain.com/docs/concepts/vectorstores/" title="å‘é‡å­˜å‚¨æ–‡æ¡£" target="_blank" style="color:#93cdfc;">>></a></h2>
        <ul>
          <li><code>QdrantVectorStore</code> | Qdrantå‘é‡æ•°æ®åº“</li>
          <li><code>Milvus</code> | é«˜æ€§èƒ½å‘é‡æœç´¢</li>
          <li><code>CacheBackedEmbeddings</code> | åµŒå…¥ç¼“å­˜ä¼˜åŒ–</li>
          <li><code>æ‰¹é‡æ“ä½œ</code> | é«˜æ•ˆçš„å‘é‡ç®¡ç†</li>
        </ul>
        <h3>é«˜çº§å‘é‡å­˜å‚¨ç¤ºä¾‹</h3>
        <pre><code class="language-python"># Qdranté…ç½®
from qdrant_client.models import Distance, VectorParams
from langchain_qdrant import QdrantVectorStore
from qdrant_client import QdrantClient

client = QdrantClient(":memory:")
vector_size = len(embeddings.embed_query("sample"))

if not client.collection_exists("test"):
    client.create_collection(
        collection_name="test",
        vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)
    )

vector_store = QdrantVectorStore(
    client=client,
    collection_name="test",
    embedding=embeddings
)

# Milvusé…ç½®
from langchain_milvus import Milvus

vector_store = Milvus(
    embedding_function=embeddings,
    connection_args={"uri": "./milvus_example.db"},
    index_params={"index_type": "FLAT", "metric_type": "L2"},
)

# åµŒå…¥ç¼“å­˜ä¼˜åŒ–
from langchain.embeddings import CacheBackedEmbeddings
from langchain.storage import LocalFileStore

store = LocalFileStore("./cache/")
cached_embedder = CacheBackedEmbeddings.from_bytes_store(
    underlying_embeddings=embeddings,
    store=store,
    namespace=embeddings.model
)

# ä½¿ç”¨ç¼“å­˜åµŒå…¥
import time
tic = time.time()
result1 = cached_embedder.embed_query("Hello, world!")
print(f"é¦–æ¬¡è°ƒç”¨è€—æ—¶ï¼š{time.time() - tic:.2f}ç§’")

tic = time.time()
result2 = cached_embedder.embed_query("Hello, world!")
print(f"ç¼“å­˜è°ƒç”¨è€—æ—¶ï¼š{time.time() - tic:.4f}ç§’")</code></pre>
        <div class="desc">é«˜çº§å‘é‡å­˜å‚¨å’Œç¼“å­˜ç­–ç•¥æå‡æ£€ç´¢æ€§èƒ½</div>
      </div>

      <div class="card">
        <h2>ğŸ§  é«˜çº§è®°å¿†ç®¡ç† <a href="https://python.langchain.com/docs/concepts/memory/" title="è®°å¿†æ–‡æ¡£" target="_blank" style="color:#93cdfc;">>></a></h2>
        <ul>
          <li><code>VectorStoreRetrieverMemory</code> | å‘é‡è®°å¿†æ£€ç´¢</li>
          <li><code>ConversationSummaryMemory</code> | å¯¹è¯æ‘˜è¦è®°å¿†</li>
          <li><code>ConversationBufferWindowMemory</code> | æ»‘åŠ¨çª—å£è®°å¿†</li>
          <li><code>ç»„åˆè®°å¿†</code> | å¤šç§è®°å¿†ç±»å‹é›†æˆ</li>
        </ul>
        <h3>è®°å¿†ç³»ç»Ÿç¤ºä¾‹</h3>
        <pre><code class="language-python">from langchain.memory import (
    ConversationBufferMemory,
    ConversationBufferWindowMemory,
    ConversationSummaryMemory,
    VectorStoreRetrieverMemory
)

# çª—å£è®°å¿†ï¼ˆä¿ç•™æœ€è¿‘5è½®å¯¹è¯ï¼‰
window_memory = ConversationBufferWindowMemory(
    k=5,
    return_messages=True,
    memory_key="chat_history"
)

# æ‘˜è¦è®°å¿†ï¼ˆé€‚åˆé•¿å¯¹è¯ï¼‰
summary_memory = ConversationSummaryMemory(
    llm=llm,
    return_messages=True,
    memory_key="chat_history"
)

# å‘é‡è®°å¿†ï¼ˆè¯­ä¹‰æ£€ç´¢ï¼‰
vector_memory = VectorStoreRetrieverMemory(
    retriever=vectorstore.as_retriever(
        search_kwargs={"k": 5, "score_threshold": 0.7}
    ),
    memory_key="relevant_history"
)

# ç»„åˆè®°å¿†ç³»ç»Ÿ
from langchain_core.runnables import RunnablePassthrough

def format_history(messages):
    return "\n".join([f"{m.type}: {m.content}" for m in messages])

# åœ¨é“¾ä¸­ä½¿ç”¨è®°å¿†
chain_with_memory = (
    {
        "relevant_history": vector_memory.load_history_variables(["input"])["relevant_history"],
        "recent_history": window_memory.load_memory_variables({})["chat_history"],
        "summary": summary_memory.load_memory_variables({})["chat_history"],
        "input": RunnablePassthrough()
    }
    | {
        "context": lambda x: f"ç›¸å…³å†å²ï¼š{x['relevant_history']}\n\nè¿‘æœŸå†å²ï¼š{x['recent_history']}\n\næ‘˜è¦ï¼š{x['summary']}",
        "input": lambda x: x["input"]
    }
    | prompt
    | llm
)

# ä¿å­˜è®°å¿†
def save_memory(inputs, outputs):
    # ä¿å­˜åˆ°æ‰€æœ‰è®°å¿†ç³»ç»Ÿ
    vector_memory.save_context(inputs, {"output": outputs})
    window_memory.save_context(inputs, {"output": outputs})

    # æ›´æ–°æ‘˜è¦è®°å¿†
    summary_memory.save_context(inputs, {"output": outputs})

# å®Œæ•´çš„è®°å¿†å¾ªç¯
result = chain_with_memory.invoke({
    "input": "æ ¹æ®æˆ‘ä»¬ä¹‹å‰çš„å¯¹è¯ï¼Œæ€»ç»“æˆ‘çš„ä¸»è¦éœ€æ±‚"
})
save_memory({"input": "æ ¹æ®æˆ‘ä»¬ä¹‹å‰çš„å¯¹è¯ï¼Œæ€»ç»“æˆ‘çš„ä¸»è¦éœ€æ±‚"}, {"output": result})</code></pre>
        <div class="desc">å¤šå±‚çº§è®°å¿†ç³»ç»Ÿæ”¯æŒé•¿æœŸå’ŒçŸ­æœŸä¿¡æ¯ç®¡ç†</div>
      </div>

      <div class="card">
        <h2>ğŸ“Š LangSmithé›†æˆä¸è¯„ä¼° <a href="https://python.langchain.com/docs/concepts/tracing/" title="LangSmithæ–‡æ¡£" target="_blank" style="color:#93cdfc;">>></a></h2>
        <ul>
          <li><code>LANGCHAIN_TRACING_V2</code> | å¯ç”¨è¿½è¸ª</li>
          <li><code>Evaluation</code> | è‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶</li>
          <li><code>StringEvaluator</code> | è‡ªå®šä¹‰è¯„ä¼°å™¨</li>
          <li><code>LLMCriteriaEvaluator</code> | LLMè¯„ä¼°å™¨</li>
        </ul>
        <h3>ç›‘æ§ä¸è¯„ä¼°ç¤ºä¾‹</h3>
        <pre><code class="language-python">import os
from langchain.evaluation import StringEvaluator, LLMCriteriaEvaluator
from langchain.evaluation.criteria import LLMCriteriaEvaluator

# é…ç½®LangSmithè¿½è¸ª
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "MyLangChainProject"
os.environ["LANGSMITH_ENDPOINT"] = "https://api.smith.langchain.com"

# è‡ªå®šä¹‰è¯„ä¼°å™¨
class CustomEvaluator(StringEvaluator):
    def evaluate_strings(self, prediction, reference, input=None):
        return {
            "score": 0.8 if prediction.lower().strip() == reference.lower().strip() else 0.2,
            "reasoning": "å­—ç¬¦ä¸²åŒ¹é…è¯„ä¼°",
            "details": f"é¢„æµ‹ï¼š{prediction}ï¼Œå‚è€ƒï¼š{reference}"
        }

# LLMè¯„ä¼°å™¨
llm_evaluator = LLMCriteriaEvaluator.from_llm(
    llm=llm,
    criteria={
        "å‡†ç¡®æ€§": "å›ç­”æ˜¯å¦å‡†ç¡®æ— è¯¯",
        "ç›¸å…³æ€§": "å›ç­”æ˜¯å¦ä¸é—®é¢˜ç›¸å…³",
        "å®Œæ•´æ€§": "å›ç­”æ˜¯å¦å®Œæ•´",
        "æ¸…æ™°åº¦": "å›ç­”æ˜¯å¦æ¸…æ™°æ˜“æ‡‚"
    }
)

# è¿è¡Œè¯„ä¼°
evaluator = CustomEvaluator()
result = evaluator.evaluate_strings(
    prediction="Hello",
    reference="hello",
    input="æ‰“æ‹›å‘¼"
)
print(f"è¯„ä¼°ç»“æœï¼š{result}")

# LLMè¯„ä¼°
llm_result = llm_evaluator.evaluate_strings(
    prediction="æœºå™¨å­¦ä¹ æ˜¯AIçš„ä¸€ä¸ªå­é¢†åŸŸ",
    reference="æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯",
    input="ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
)
print(f"LLMè¯„ä¼°ç»“æœï¼š{llm_result}")

# æ‰¹é‡è¯„ä¼°
from langchain.evaluation import load_evaluator

evaluator = load_evaluator("labeled_string_string_distance")
dataset = [
    {"input": "é—®é¢˜1", "prediction": "ç­”æ¡ˆ1", "reference": "æ ‡å‡†ç­”æ¡ˆ1"},
    {"input": "é—®é¢˜2", "prediction": "ç­”æ¡ˆ2", "reference": "æ ‡å‡†ç­”æ¡ˆ2"}
]

results = []
for item in dataset:
    result = evaluator.evaluate_strings(**item)
    results.append(result)

# è®¡ç®—å¹³å‡åˆ†æ•°
avg_score = sum(r["score"] for r in results) / len(results)
print(f"å¹³å‡è¯„ä¼°åˆ†æ•°ï¼š{avg_score:.2f}")</code></pre>
        <div class="desc">å®Œæ•´çš„ç›‘æ§å’Œè¯„ä¼°ä½“ç³»ä¿éšœåº”ç”¨è´¨é‡</div>
      </div>

      <div class="card">
        <h2>ğŸŒŠ é«˜çº§æµå¼å¤„ç† <a href="https://python.langchain.com/docs/concepts/streaming/" title="æµå¼æ–‡æ¡£" target="_blank" style="color:#93cdfc;">>></a></h2>
        <ul>
          <li><code>JsonOutputParser</code> | JSONæµå¼è§£æ</li>
          <li><code>è‡ªå®šä¹‰è§£æå™¨</code> | å®æ—¶æ•°æ®å¤„ç†</li>
          <li><code>å›è°ƒæœºåˆ¶</code> | æµå¼äº‹ä»¶å¤„ç†</li>
          <li><code>å¼‚æ­¥æµ</code> | é«˜æ€§èƒ½æµå¤„ç†</li>
        </ul>
        <h3>æµå¼å¤„ç†ç¤ºä¾‹</h3>
        <pre><code class="language-python">from langchain_core.output_parsers import JsonOutputParser
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain_core.callbacks import BaseCallbackHandler

class CustomStreamingHandler(BaseCallbackHandler):
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        print(token, end="", flush=True)

    def on_llm_end(self, response, **kwargs) -> None:
        print("\n--- ç”Ÿæˆå®Œæˆ ---")

# JSONæµå¼è¾“å‡º
json_parser = JsonOutputParser()
json_chain = prompt | llm | json_parser

async def stream_json_response():
    print("JSONæµå¼è¾“å‡ºï¼š")
    async for chunk in json_chain.astream({"input": "ç”Ÿæˆç”¨æˆ·JSONæ•°æ®"}):
        print(f"æ”¶åˆ°ï¼š{chunk}", flush=True)

# æ–‡æœ¬æµå¼å¤„ç†
streaming_handler = CustomStreamingHandler()

chain = prompt | llm
result = chain.invoke(
    {"input": "å†™ä¸€ä¸ªç®€çŸ­çš„æ•…äº‹"},
    callbacks=[streaming_handler]
)

# ç»“æ„åŒ–æ•°æ®æµ
class DataExtractor(BaseModel):
    title: str
    items: List[str]
    priority: int

structured_parser = JsonOutputParser(pydantic_object=DataExtractor)
structured_chain = prompt | llm | structured_parser

async def stream_structured_data():
    print("\nç»“æ„åŒ–æ•°æ®æµï¼š")
    buffer = ""
    async for chunk in structured_chain.astream({"input": "æå–é¡¹ç›®æ¸…å•"}):
        if chunk:
            buffer += str(chunk)
            print(f"éƒ¨åˆ†æ•°æ®ï¼š{chunk}")
        else:
            print(f"å®Œæ•´æ•°æ®ï¼š{buffer}")

# è¿è¡Œæµå¼ç¤ºä¾‹
import asyncio

async def main():
    print("=== æµå¼å¤„ç†æ¼”ç¤º ===\n")

    await stream_json_response()

    print("\n" + "="*50 + "\n")

    await stream_structured_data()

# è¿è¡Œ
asyncio.run(main())</code></pre>
        <div class="desc">å¼ºå¤§çš„æµå¼å¤„ç†èƒ½åŠ›æ”¯æŒå®æ—¶åº”ç”¨</div>
      </div>

      <div class="card">
        <h2>ğŸ“¤ è¾“å‡ºè§£æå™¨æ‰©å±• <a href="https://python.langchain.com/docs/concepts/output_parsers/" title="è¾“å‡ºè§£ææ–‡æ¡£" target="_blank" style="color:#93cdfc;">>></a></h2>
        <ul>
          <li><code>PydanticOutputParser</code> | ç»“æ„åŒ–æ•°æ®è§£æ</li>
          <li><code>RegexParser</code> | æ­£åˆ™è¡¨è¾¾å¼è§£æ</li>
          <li><code>EnumOutputParser</code> | æšä¸¾ç±»å‹è§£æ</li>
          <li><code>ListOutputParser</code> | åˆ—è¡¨æ•°æ®è§£æ</li>
        </ul>
        <h3>é«˜çº§è§£æå™¨ç¤ºä¾‹</h3>
        <pre><code class="language-python">from langchain.output_parsers import (
    PydanticOutputParser,
    RegexParser,
    EnumOutputParser,
    ListOutputParser
)

# Pydanticè§£æå™¨
from pydantic import BaseModel, Field, validator

class ProductInfo(BaseModel):
    name: str = Field(description="äº§å“åç§°")
    price: float = Field(description="äº§å“ä»·æ ¼")
    category: str = Field(description="äº§å“ç±»åˆ«")
    in_stock: bool = Field(description="æ˜¯å¦æœ‰åº“å­˜")

    @validator('price')
    def price_must_be_positive(cls, v):
        if v <= 0:
            raise ValueError('ä»·æ ¼å¿…é¡»ä¸ºæ­£æ•°')
        return v

product_parser = PydanticOutputParser(pydantic_object=ProductInfo)

# æ­£åˆ™è¡¨è¾¾å¼è§£æå™¨
regex_parser = RegexParser(
    regex=r"ä»·æ ¼ï¼š\s*(\d+(?:\.\d+)?)\s*å…ƒ",
    output_keys=["price"],
    default_output_key="price"
)

# æšä¸¾è§£æå™¨
enum_parser = EnumOutputParser(
    enum=["é«˜", "ä¸­", "ä½"],
    default="ä¸­"
)

# åˆ—è¡¨è§£æå™¨
list_parser = ListOutputParser()

# ç»„åˆè§£æå™¨
class ComplexAnalysis(BaseModel):
    sentiment: str = Field(description="æƒ…æ„Ÿå€¾å‘ï¼ˆæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰")
    keywords: List[str] = Field(description="å…³é”®è¯åˆ—è¡¨")
    confidence: float = Field(description="ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰")

complex_parser = PydanticOutputParser(pydantic_object=ComplexAnalysis)

# ä½¿ç”¨ç¤ºä¾‹
chain = prompt | llm | complex_parser

result = chain.invoke({
    "input": "åˆ†æè¿™æ®µæ–‡æœ¬ï¼šè¿™ä¸ªäº§å“è´¨é‡å¾ˆå¥½ï¼Œä»·æ ¼å®æƒ ï¼Œç‰©è¶…æ‰€å€¼"
})

print(f"æƒ…æ„Ÿï¼š{result.sentiment}")
print(f"å…³é”®è¯ï¼š{result.keywords}")
print(f"ç½®ä¿¡åº¦ï¼š{result.confidence:.2f}")

# é”™è¯¯å¤„ç†
try:
    result = product_parser.parse("äº§å“åç§°ï¼šæ‰‹æœºï¼Œä»·æ ¼ï¼š-500å…ƒ")
except Exception as e:
    print(f"è§£æé”™è¯¯ï¼š{e}")
    # ä½¿ç”¨é»˜è®¤å€¼é‡è¯•
    corrected_result = ProductInfo(
        name="æ‰‹æœº",
        price=500.0,  # ä¿®æ­£è´Ÿä»·æ ¼
        category="ç”µå­äº§å“",
        in_stock=True
    )
    print(f"ä¿®æ­£åçš„ç»“æœï¼š{corrected_result}")</code></pre>
        <div class="desc">ç±»å‹å®‰å…¨çš„è¾“å‡ºè§£ææ”¯æŒå¤æ‚ç»“æ„æ•°æ®</div>
      </div>

      <div class="card">
        <h2>ğŸ“š æœ€ä½³å®è·µä¸æ¨¡å¼ <a href="https://python.langchain.com/docs/tutorials/" title="æ•™ç¨‹æ–‡æ¡£" target="_blank" style="color:#93cdfc;">>></a></h2>
        <ul>
          <li><code>é”™è¯¯å¤„ç†</code> | å®Œæ•´çš„å¼‚å¸¸å¤„ç†æœºåˆ¶</li>
          <li><code>æ€§èƒ½ä¼˜åŒ–</code> | ç¼“å­˜å’Œæ‰¹å¤„ç†ç­–ç•¥</li>
          <li><code>ç±»å‹å®‰å…¨</code> | Pydanticæ¨¡å‹éªŒè¯</li>
          <li><code>å¼‚æ­¥ç¼–ç¨‹</code> | å……åˆ†åˆ©ç”¨å¼‚æ­¥ç‰¹æ€§</li>
        </ul>
        <h3>æœ€ä½³å®è·µç¤ºä¾‹</h3>
        <pre><code class="language-python">from typing import Optional, Dict, Any
import asyncio
from functools import wraps

# é”™è¯¯è£…é¥°å™¨
def handle_errors(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        try:
            return await func(*args, **kwargs)
        except Exception as e:
            print(f"é”™è¯¯ {func.__name__}: {e}")
            return {"error": str(e), "success": False}
    return wrapper

# é‡è¯•æœºåˆ¶
async def retry_with_backoff(
    func,
    max_retries: int = 3,
    initial_delay: float = 1.0
):
    for attempt in range(max_retries):
        try:
            return await func()
        except Exception as e:
            if attempt == max_retries - 1:
                raise e
            delay = initial_delay * (2 ** attempt)
            print(f"é‡è¯• {attempt + 1}/{max_retries}ï¼Œå»¶è¿Ÿ {delay:.1f}s")
            await asyncio.sleep(delay)

# ç¼“å­˜è£…é¥°å™¨
_cache = {}
def cached_result(ttl_seconds: int = 300):
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            key = f"{func.__name__}_{str(args)}_{str(kwargs)}"

            # æ£€æŸ¥ç¼“å­˜
            if key in _cache:
                cached_item = _cache[key]
                import time
                if time.time() - cached_item["timestamp"] < ttl_seconds:
                    print(f"ä½¿ç”¨ç¼“å­˜ç»“æœï¼š{key}")
                    return cached_item["result"]

            # è®¡ç®—æ–°ç»“æœ
            result = await func(*args, **kwargs)

            # å­˜å‚¨åˆ°ç¼“å­˜
            import time
            _cache[key] = {
                "result": result,
                "timestamp": time.time()
            }
            return result
        return wrapper
    return decorator

# åº”ç”¨æœ€ä½³å®è·µ
@handle_errors
@cached_result(ttl_seconds=600)
async def expensive_llm_call(query: str) -> Dict[str, Any]:
    """è°ƒç”¨LLMçš„åŒ…è£…å‡½æ•°ï¼ŒåŒ…å«é”™è¯¯å¤„ç†å’Œç¼“å­˜"""
    response = await llm.ainvoke(query)

    # éªŒè¯å“åº”
    if not response or not response.content:
        raise ValueError("LLMè¿”å›ç©ºå“åº”")

    return {
        "content": response.content,
        "model": getattr(response, 'model', 'unknown'),
        "tokens_used": getattr(response, 'usage', {}).get('total_tokens', 0)
    }

# æ‰¹å¤„ç†ä¼˜åŒ–
async def batch_process(items: list, batch_size: int = 5) -> list:
    """æ‰¹é‡å¤„ç†ä»¥æé«˜æ€§èƒ½"""
    results = []

    for i in range(0, len(items), batch_size):
        batch = items[i:i + batch_size]
        batch_tasks = [expensive_llm_call(item) for item in batch]

        # å¹¶è¡Œå¤„ç†æ‰¹æ¬¡
        batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)

        # å¤„ç†ç»“æœå’Œå¼‚å¸¸
        for result in batch_results:
            if isinstance(result, Exception):
                results.append({"error": str(result), "success": False})
            else:
                results.append(result)

    return results

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    queries = [
        "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
        "è§£é‡Šæ·±åº¦å­¦ä¹ çš„åŸç†",
        "ç¥ç»ç½‘ç»œæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ",
        "è®¡ç®—æœºè§†è§‰çš„åº”ç”¨æœ‰å“ªäº›ï¼Ÿ",
        "è‡ªç„¶è¯­è¨€å¤„ç†çš„æŒ‘æˆ˜æ˜¯ä»€ä¹ˆï¼Ÿ"
    ]

    print("=== æ‰¹å¤„ç†ç¤ºä¾‹ ===")
    results = await batch_process(queries, batch_size=3)

    for i, (query, result) in enumerate(zip(queries, results)):
        print(f"{i+1}. é—®é¢˜ï¼š{query[:30]}...")
        if result.get("success"):
            print(f"   å›ç­”ï¼š{result['content'][:50]}...")
            print(f"   ä½¿ç”¨æ¨¡å‹ï¼š{result['model']}")
            print(f"   Tokenæ•°ï¼š{result['tokens_used']}")
        else:
            print(f"   é”™è¯¯ï¼š{result['error']}")

# è¿è¡Œæœ€ä½³å®è·µç¤ºä¾‹
asyncio.run(main())</code></pre>
        <div class="desc">å®Œæ•´çš„é”™è¯¯å¤„ç†ã€æ€§èƒ½ä¼˜åŒ–å’Œç¼“å­˜ç­–ç•¥</div>
      </div>

      <div class="card">
        <h2>ğŸ”— å­¦ä¹ èµ„æºä¸å·¥å…· <a href="https://python.langchain.com/docs/" title="å®˜æ–¹æ–‡æ¡£é¦–é¡µ" target="_blank" style="color:#93cdfc;">>></a></h2>
        <ul>
          <li><code>å®˜æ–¹æ–‡æ¡£</code> | https://python.langchain.com/docs/</li>
          <li><code>LangSmith</code> | https://smith.langchain.com/</li>
          <li><code>GitHubä»“åº“</code> | https://github.com/langchain-ai/langchain</li>
          <li><code>ç¤¾åŒºè®ºå›</code> | https://discord.gg/langchain</li>
        </ul>
        <h3>å¼€å‘å·¥å…·é›†æˆ</h3>
        <pre><code class="language-bash"># å¼€å‘ç¯å¢ƒè®¾ç½®
pip install langchain[dev]  # å®‰è£…å¼€å‘ä¾èµ–

# ä»£ç è´¨é‡å·¥å…·
pip install black flake8 mypy  # ä»£ç æ ¼å¼åŒ–å’Œæ£€æŸ¥

# æµ‹è¯•å·¥å…·
pip install pytest pytest-asyncio  # å¼‚æ­¥æµ‹è¯•æ”¯æŒ

# æ€§èƒ½åˆ†æ
pip install memory-profiler  # å†…å­˜åˆ†æ
pip install line-profiler  # è¡Œçº§æ€§èƒ½åˆ†æ

# VSCodeæ‰©å±•æ¨è
# - LangChain Assistant
# - Python
# - Pylance
# - GitLens

# å¸¸ç”¨å¼€å‘æ¨¡å¼
# 1. æ¨¡å—åŒ–å¼€å‘
#    - æ¯ä¸ªåŠŸèƒ½æ¨¡å—ç‹¬ç«‹å¼€å‘
#    - ä½¿ç”¨TypeScriptæç¤ºå¢å¼ºç±»å‹å®‰å…¨
#    - å®ç°å®Œæ•´çš„é”™è¯¯å¤„ç†

# 2. è¿­ä»£æµ‹è¯•
#    - ä½¿ç”¨LangSmithè¿½è¸ªå’Œè°ƒè¯•
#    - ç¼–å†™è‡ªåŠ¨åŒ–è¯„ä¼°è„šæœ¬
#    - æ€§èƒ½åŸºå‡†æµ‹è¯•

# 3. æŒç»­é›†æˆ
#    - è‡ªåŠ¨åŒ–æµ‹è¯•æµæ°´çº¿
#    - ä»£ç è´¨é‡æ£€æŸ¥
#    - æ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆ

# æ¨èå­¦ä¹ è·¯å¾„
# 1. åŸºç¡€æ¦‚å¿µï¼ˆ1-2å‘¨ï¼‰
#    - ç†è§£LCELé“¾å¼è°ƒç”¨
#    - æŒæ¡Promptæ¨¡æ¿
#    - å­¦ä¹ åŸºæœ¬å·¥å…·ä½¿ç”¨

# 2. è¿›é˜¶åŠŸèƒ½ï¼ˆ2-3å‘¨ï¼‰
#    - LangGraphä»£ç†ç³»ç»Ÿ
#    - é«˜çº§è®°å¿†ç®¡ç†
#    - å¤æ‚è¾“å‡ºè§£æ

# 3. å®æˆ˜é¡¹ç›®ï¼ˆ3-4å‘¨ï¼‰
#    - æ„å»ºRAGåº”ç”¨
#    - å¼€å‘å¤šä»£ç†ç³»ç»Ÿ
#    - ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²</code></pre>
        <div class="desc">å®Œæ•´çš„å¼€å‘ç”Ÿæ€å’Œå­¦ä¹ è·¯å¾„æŒ‡å¯¼</div>
      </div>
    </div>
  </div>

  <script>
    document.getElementById('columnWidth').addEventListener('input', function(e) {
      const width = e.target.value;
      document.getElementById('widthVal').textContent = width + 'px';
      const columns = document.getElementById('columns');
      columns.style.columnWidth = width + 'px';
    });

    // Prism.js ä»£ç é«˜äº®åˆå§‹åŒ–
    document.addEventListener('DOMContentLoaded', function() {
      // ç¡®ä¿ Prism å·²åŠ è½½
      if (window.Prism) {
        // é«˜äº®æ‰€æœ‰ä»£ç å—
        Prism.highlightAll();

        // å¯é€‰ï¼šæ·»åŠ è¡Œå·æ˜¾ç¤º
        Prism.plugins.lineNumbers = false; // ç¦ç”¨è¡Œå·ä»¥ä¿æŒç®€æ´

        console.log('ä»£ç é«˜äº®å·²å¯ç”¨');
      }
    });
  </script>
</body>
</html>