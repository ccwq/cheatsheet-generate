# LangChain Cheatsheet é‡æ„æŒ‡å¯¼

## ğŸ“‹ å®˜æ–¹æ–‡æ¡£ç« èŠ‚æ•°æ®å¯¹æ¯”åˆ†æ

### LangChain å®˜æ–¹æ–‡æ¡£ç»“æ„
æ ¹æ®langchain-ai/langchainå®˜æ–¹æ–‡æ¡£ï¼Œä¸»è¦åŒ…å«ï¼š

- **Installation** - å¤šç§å®‰è£…æ–¹å¼ï¼ˆpip, uv, condaç­‰ï¼‰
- **Core Concepts** - æ ¸å¿ƒæ¦‚å¿µï¼ˆLLMs, Prompts, Chains, Agents, Memoryï¼‰
- **Model I/O** - æ¨¡å‹è¾“å…¥è¾“å‡ºå¤„ç†
- **Data Connection** - æ•°æ®è¿æ¥ï¼ˆDocument Loaders, Text Splitters, Vector Stores, Retrieversï¼‰
- **Chains** - é“¾å¼è°ƒç”¨å’Œç»„åˆ
- **Agents** - ä»£ç†ç³»ç»Ÿå’Œå·¥å…·è°ƒç”¨
- **Memory** - è®°å¿†ç®¡ç†
- **Callbacks** - å›è°ƒå’Œç›‘æ§
- **Evaluation** - è¯„ä¼°å’Œè°ƒè¯•

### å½“å‰æœ¬åœ° Cheatsheet å†…å®¹åˆ†æ

#### âœ… å·²åŒ…å«çš„è‰¯å¥½å†…å®¹
1. **å®‰è£…ä¸é…ç½®** - åŸºæœ¬çš„ pip å®‰è£…å‘½ä»¤
2. **æ¨¡å‹é›†æˆ** - OpenAI å’Œ Anthropic æ¨¡å‹åˆå§‹åŒ–
3. **Prompt æ¨¡æ¿** - åŸºç¡€æ¨¡æ¿å’ŒèŠå¤©æ¨¡æ¿
4. **LCEL é“¾å¼è°ƒç”¨** - åŸºç¡€é“¾å’Œå¹¶è¡Œæ‰§è¡Œ
5. **Agents ä»£ç†** - ç®€å•ä»£ç†åˆ›å»ºå’Œå·¥å…·è£…é¥°å™¨
6. **Tools å·¥å…·** - åŸºç¡€å·¥å…·å®šä¹‰
7. **æ–‡æ¡£åŠ è½½å™¨** - éƒ¨åˆ†åŠ è½½å™¨ç¤ºä¾‹
8. **æ–‡æœ¬åˆ†å‰²å™¨** - åŸºç¡€åˆ†å‰²æ–¹æ³•
9. **Embeddings** - OpenAI å’Œ HuggingFace åµŒå…¥
10. **Vector Stores** - FAISS å’Œ Chroma åŸºç¡€ç”¨æ³•
11. **RAG** - åŸºç¡€æ£€ç´¢å¢å¼ºç”Ÿæˆ
12. **å…¶ä»–åŠŸèƒ½æ¨¡å—** - è¾“å‡ºè§£æã€è®°å¿†ã€å›è°ƒç­‰

#### âŒ éœ€è¦è¡¥å……çš„å…³é”®å†…å®¹

### ğŸ”§ Installation è¡¥å……å†…å®¹

1. **ç°ä»£å®‰è£…æ–¹æ³•**ï¼š
```bash
# ä½¿ç”¨ uv (æ¨è)
uv add langchain
uv add --prerelease=allow langchain

# ä½¿ç”¨ pip
pip install --pre -U langchain

# å®‰è£…ç‰¹å®šé›†æˆåŒ…
pip install langchain-openai langchain-anthropic
pip install langchain-community
pip install langchain-core

# å‘é‡å­˜å‚¨
pip install chromadb faiss-cup
pip install langchain-qdrant
pip install langchain-milvus
```

2. **LangChain v1.0 è¿ç§»è¯´æ˜**ï¼š
```bash
# å¦‚æœéœ€è¦æ—§ç‰ˆåŠŸèƒ½
pip install langchain-classic
uv add langchain-classic
```

### ğŸ¤– Models è¡¥å……å†…å®¹

1. **ç»Ÿä¸€çš„æ¨¡å‹åˆå§‹åŒ–**ï¼š
```python
from langchain.chat_models import init_chat_model
from langchain.embeddings import init_embeddings

# è‡ªåŠ¨æ ¹æ®æ¨¡å‹å­—ç¬¦ä¸²é€‰æ‹©æä¾›å•†
llm = init_chat_model("openai:gpt-4o-mini")
embeddings = init_embeddings("openai:text-embedding-3-large")
```

2. **æ›´å¤šæ¨¡å‹æä¾›å•†**ï¼š
```python
# Google
from langchain_google_vertexai import ChatVertexAI
llm = ChatVertexAI(model="gemini-pro")

# Cohere
from langchain_cohere import ChatCohere
llm = ChatCohere(model="command-r-plus")

# Groq
from langchain_groq import ChatGroq
llm = ChatGroq(model="llama-3.1-70b-versatile")
```

3. **é«˜çº§æ¨¡å‹é…ç½®**ï¼š
```python
# é…ç½®å‚æ•°
llm = ChatOpenAI(
    model="gpt-4o",
    temperature=0.7,
    max_tokens=1000,
    streaming=True,
    timeout=30,
    max_retries=3,
    model_kwargs={"response_format": {"type": "json_object"}}
)
```

### ğŸ“ Prompts è¡¥å……å†…å®¹

1. **æ›´å¤šæ¨¡æ¿ç±»å‹**ï¼š
```python
from langchain_core.prompts import (
    PromptTemplate,
    ChatPromptTemplate,
    FewShotPromptTemplate,
    PipelinePromptTemplate
)

# Few-shot å­¦ä¹ 
examples = [
    {"input": "2+2", "output": "4"},
    {"input": "3+3", "output": "6"}
]

few_shot_prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=PromptTemplate.from_template("è¾“å…¥: {input} è¾“å‡º: {output}"),
    prefix="è®¡ç®—ä»¥ä¸‹æ•°å­¦é—®é¢˜ï¼š",
    suffix="è¾“å…¥: {input}",
    input_variables=["input"]
)
```

2. **ç»„åˆæ¨¡æ¿**ï¼š
```python
from langchain_core.prompts.pipeline import PipelinePromptTemplate

# å¤šçº§æ¨¡æ¿ç»„åˆ
full_template = """èƒŒæ™¯ï¼š{background}
ä»»åŠ¡ï¼š{task}
ä¸Šä¸‹æ–‡ï¼š{context}
é—®é¢˜ï¼š{question}
ç­”æ¡ˆï¼š"""

prompt = PromptTemplate.from_template(full_template)
```

### ğŸ”— Chains è¡¥å……å†…å®¹

1. **é«˜çº§é“¾æ¨¡å¼**ï¼š
```python
from langchain_core.chains import (
    create_structured_output_chain,
    create_openai_tools_chain,
    create_retrieval_chain
)

# ç»“æ„åŒ–è¾“å‡ºé“¾
from pydantic import BaseModel, Field

class Answer(BaseModel):
    answer: str = Field(description="é—®é¢˜çš„ç­”æ¡ˆ")
    confidence: float = Field(description="ç­”æ¡ˆçš„ç½®ä¿¡åº¦")

structured_chain = create_structured_output_chain(
    llm=llm,
    prompt=prompt,
    output_schema=Answer
)
```

2. **å¤æ‚é“¾ç»„åˆ**ï¼š
```python
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_history_aware_retriever_chain

# å†å²æ„ŸçŸ¥æ£€ç´¢å™¨
retriever_chain = create_history_aware_retriever_chain(
    llm=llm,
    retriever=retriever,
    rephrase_prompt=ChatPromptTemplate.from_template("""
    æ ¹æ®èŠå¤©å†å²å’Œæœ€æ–°é—®é¢˜ï¼Œç”Ÿæˆæ£€ç´¢æŸ¥è¯¢ã€‚
    èŠå¤©å†å²ï¼š{chat_history}
    æœ€æ–°é—®é¢˜ï¼š{input}
    æ£€ç´¢æŸ¥è¯¢ï¼š
    """)
)
```

### ğŸ¯ Agents è¡¥å……å†…å®¹

1. **LangGraph ä»£ç†**ï¼š
```python
from langgraph.prebuilt import create_react_agent
from langchain.tools import tool

# åˆ›å»º React ä»£ç†
agent = create_react_agent(
    model=llm,
    tools=tools,
    state_modifier="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚"
)

# æ‰§è¡Œä»£ç†
result = agent.invoke({
    "messages": [
        {"role": "user", "content": "è®¡ç®— 15 * 23"}
    ]
})
```

2. **å·¥å…·ç±»å‹å’Œé…ç½®**ï¼š
```python
from langchain.tools import tool
from typing import List, Dict
import requests

@tool
def search_web(query: str) -> List[Dict]:
    """æœç´¢ç½‘ç»œä¿¡æ¯"""
    response = requests.get(f"https://api.example.com/search?q={query}")
    return response.json().get("results", [])

@tool
def calculator(expression: str) -> float:
    """è®¡ç®—æ•°å­¦è¡¨è¾¾å¼"""
    return eval(expression)

tools = [search_web, calculator]
```

### ğŸ’¾ Vector Stores è¡¥å……å†…å®¹

1. **æ›´å¤šå‘é‡å­˜å‚¨é€‰é¡¹**ï¼š
```python
# Qdrant
from qdrant_client.models import Distance, VectorParams
from langchain_qdrant import QdrantVectorStore

client = QdrantClient(":memory:")
vector_size = len(embeddings.embed_query("sample"))

if not client.collection_exists("test"):
    client.create_collection(
        collection_name="test",
        vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)
    )

vector_store = QdrantVectorStore(
    client=client,
    collection_name="test",
    embedding=embeddings
)

# Milvus
from langchain_milvus import Milvus

vector_store = Milvus(
    embedding_function=embeddings,
    connection_args={"uri": "./milvus_example.db"},
    index_params={"index_type": "FLAT", "metric_type": "L2"},
)
```

2. **åµŒå…¥ç¼“å­˜ä¼˜åŒ–**ï¼š
```python
from langchain.embeddings import CacheBackedEmbeddings
from langchain.storage import LocalFileStore

# ç¼“å­˜åµŒå…¥ä»¥æå‡æ€§èƒ½
store = LocalFileStore("./cache/")
cached_embedder = CacheBackedEmbeddings.from_bytes_store(
    underlying_embeddings=embeddings,
    store=store,
    namespace=embeddings.model
)
```

### ğŸ§  Memory è¡¥å……å†…å®¹

1. **å¤šæ ·åŒ–è®°å¿†ç±»å‹**ï¼š
```python
from langchain.memory import (
    ConversationBufferMemory,
    ConversationBufferWindowMemory,
    ConversationSummaryMemory,
    VectorStoreRetrieverMemory
)

# çª—å£è®°å¿†
window_memory = ConversationBufferWindowMemory(
    k=5,  # ä¿ç•™æœ€è¿‘5è½®å¯¹è¯
    return_messages=True
)

# æ€»ç»“è®°å¿†
summary_memory = ConversationSummaryMemory(
    llm=llm,
    return_messages=True
)

# å‘é‡è®°å¿†
vector_memory = VectorStoreRetrieverMemory(
    retriever=vectorstore.as_retriever(search_kwargs={"k": 2}),
    memory_key="chat_history"
)
```

### ğŸ“Š LangSmith é›†æˆè¡¥å……å†…å®¹

1. **è¿½è¸ªå’Œç›‘æ§é…ç½®**ï¼š
```python
import os
from langchain.callbacks.tracers import LangChainTracer
from langchain.callbacks.manager import CallbackManager

# é…ç½® LangSmith
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "MyProject"

# åˆ›å»ºè¿½è¸ªå™¨
tracer = LangChainTracer()
callback_manager = CallbackManager([tracer])

# åœ¨é“¾ä¸­ä½¿ç”¨
result = chain.invoke(
    {"input": "æµ‹è¯•è¾“å…¥"},
    callbacks=[callback_manager]
)
```

2. **è¯„ä¼°å’Œè°ƒè¯•**ï¼š
```python
from langchain.evaluation import StringEvaluator
from langchain.evaluation.criteria import LLMCriteriaEvaluator

# è‡ªå®šä¹‰è¯„ä¼°å™¨
class CustomEvaluator(StringEvaluator):
    def evaluate_strings(self, prediction, reference, input=None):
        return {
            "score": 0.8 if prediction.lower() == reference.lower() else 0.2,
            "reasoning": "å­—ç¬¦ä¸²åŒ¹é…è¯„ä¼°"
        }

evaluator = CustomEvaluator()
result = evaluator.evaluate_strings(
    prediction="Hello",
    reference="hello",
    input="æ‰“æ‹›å‘¼"
)
```

### ğŸŒŠ Streaming è¡¥å……å†…å®¹

1. **é«˜çº§æµå¼å¤„ç†**ï¼š
```python
from langchain_core.output_parsers import JsonOutputParser
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

# JSON æµå¼è¾“å‡º
json_parser = JsonOutputParser()
chain = prompt | llm | json_parser

# æµå¼æ‰§è¡Œ
async def stream_json_response():
    async for chunk in chain.astream({"input": "ç”ŸæˆJSONæ•°æ®"}):
        print(chunk, end="", flush=True)

# è¿è¡Œ
import asyncio
asyncio.run(stream_json_response())
```

### ğŸ“¤ Output Parsers è¡¥å……å†…å®¹

1. **å¤šæ ·åŒ–è§£æå™¨**ï¼š
```python
from langchain.output_parsers import (
    PydanticOutputParser,
    RegexParser,
    EnumOutputParser,
    ListOutputParser
)

# Pydantic è§£æå™¨
from pydantic import BaseModel, Field

class Person(BaseModel):
    name: str = Field(description="å§“å")
    age: int = Field(description="å¹´é¾„")
    hobbies: List[str] = Field(description="çˆ±å¥½")

parser = PydanticOutputParser(pydantic_object=Person)

# æ­£åˆ™è¡¨è¾¾å¼è§£æå™¨
regex_parser = RegexParser(
    regex=r"ä»·æ ¼ï¼š\s*(\d+)\s*å…ƒ",
    output_keys=["price"]
)
```

## ğŸ› ï¸ é‡æ„å®æ–½å»ºè®®

### 1. å†…å®¹ç»“æ„ä¼˜åŒ–
- æŒ‰å®˜æ–¹æ–‡æ¡£çš„æ ‡å‡†æ¨¡å—ç»„ç»‡å†…å®¹
- æ¯ä¸ªæ¨¡å—æŒ‰åŸºç¡€â†’è¿›é˜¶â†’å®è·µçš„é¡ºåºç¼–æ’
- å¢åŠ æ›´å¤šå®ç”¨çš„ä»£ç ç¤ºä¾‹å’Œæœ€ä½³å®è·µ

### 2. æ–°å¢é‡è¦æ¨¡å—
- **LangGraph** - æ–°çš„ä»£ç†æ¡†æ¶
- **Evaluation** - è¯„ä¼°å’Œæµ‹è¯•æ–¹æ³•
- **Production Deployment** - ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æŒ‡å—
- **Performance Optimization** - æ€§èƒ½ä¼˜åŒ–æŠ€å·§
- **Error Handling** - å®Œå–„çš„é”™è¯¯å¤„ç†

### 3. ç‰ˆæœ¬æ›´æ–°å†…å®¹
- LangChain v1.0 çš„æ–°ç‰¹æ€§è¯´æ˜
- create_agent æ–°æ ‡å‡†
- ç»Ÿä¸€å‘½åç©ºé—´çš„å˜åŒ–
- è¿ç§»æŒ‡å—å’Œå…¼å®¹æ€§è¯´æ˜

### 4. å®ç”¨å·¥å…·é›†æˆ
- æ›´å¤šå‘é‡å­˜å‚¨çš„é…ç½®ç¤ºä¾‹
- ä¸åŒLLMæä¾›å•†çš„é…ç½®å¯¹æ¯”
- å¼€å‘ç¯å¢ƒè®¾ç½®å’Œè°ƒè¯•æŠ€å·§
- æˆæœ¬ä¼˜åŒ–å’Œæ€§èƒ½ç›‘æ§

### 5. å­¦ä¹ èµ„æºå®Œå–„
- å®˜æ–¹æ•™ç¨‹å’Œç¤ºä¾‹é¡¹ç›®é“¾æ¥
- ç¤¾åŒºèµ„æºå’Œæœ€ä½³å®è·µ
- å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
- è¿›é˜¶å­¦ä¹ è·¯å¾„æ¨è

## ğŸ“ ä¼˜å…ˆçº§å»ºè®®

1. **é«˜ä¼˜å…ˆçº§**ï¼šLangGraph ä»£ç†ç³»ç»Ÿã€Evaluation è¯„ä¼°æ¨¡å—
2. **é«˜ä¼˜å…ˆçº§**ï¼šç°ä»£å®‰è£…æ–¹æ³•ã€æ¨¡å‹ç»Ÿä¸€åˆå§‹åŒ–API
3. **ä¸­ä¼˜å…ˆçº§**ï¼šé«˜çº§é“¾ç»„åˆã€å¤šæ ·åŒ–è®°å¿†ç±»å‹
4. **ä¸­ä¼˜å…ˆçº§**ï¼šå‘é‡å­˜å‚¨æ‰©å±•ã€æµå¼å¤„ç†ä¼˜åŒ–
5. **ä½ä¼˜å…ˆçº§**ï¼šç”Ÿäº§éƒ¨ç½²ã€æ€§èƒ½ä¼˜åŒ–æŠ€å·§

## ğŸ¯ éªŒè¯è¦ç‚¹

1. å†…å®¹è¦†ç›– LangChain v1.0 æœ€æ–°ç‰¹æ€§
2. ä»£ç ç¤ºä¾‹çš„å®Œæ•´æ€§å’Œå¯è¿è¡Œæ€§
3. ä¸å®˜æ–¹æ–‡æ¡£çš„åŒæ­¥æ€§
4. ä¸­æ–‡æœ¯è¯­çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§
5. é¡µé¢ç»“æ„çš„é€»è¾‘æ€§å’Œç”¨æˆ·ä½“éªŒ
6. å®ç”¨æ€§å’Œæœ€ä½³å®è·µçš„æŒ‡å¯¼ä»·å€¼

## ğŸ”— å‚è€ƒèµ„æºé“¾æ¥

- å®˜æ–¹æ–‡æ¡£ï¼šhttps://python.langchain.com/
- GitHubä»“åº“ï¼šhttps://github.com/langchain-ai/langchain
- LangSmithï¼šhttps://smith.langchain.com/
- ç¤¾åŒºè®ºå›ï¼šhttps://discord.gg/langchain